{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Fine-tuning BertModel.from_pretrained(\"bert-base-uncased\") (BERT)\n",
        "\n",
        "amber pan\n",
        "08/15/2025"
      ],
      "metadata": {
        "id": "z7M4Uj1LldKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moA_qbxcGlCV"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "id": "77lpqHL4ydV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample record-level training data\n",
        "record_data = pd.DataFrame({\n",
        "    \"record_id\": [0, 1, 2],\n",
        "    # \"transcript\": [\"I like cat\", \"You are [pause] funny\", \"It rained\"],\n",
        "    \"transcript\": [\"I like cats\", \"You are funny\", \"It rained\"],\n",
        "    \"humor_type\": [3, 1, 2],\n",
        "    \"humor_score\": [2.0, 3.0, 1.0],\n",
        "})\n",
        "\n",
        "audio_features = pd.DataFrame({\n",
        "    \"record_id\": [0, 1, 2],\n",
        "    \"audio_feature1\": [0.08, 0.51, 0.17],\n",
        "    \"audio_feature2\": [0.51, 0.19, 0.67]\n",
        "})\n",
        "\n",
        "# Merge on record_id\n",
        "df = pd.merge(record_data, audio_features, on=\"record_id\")\n",
        "df\n"
      ],
      "metadata": {
        "id": "euuqWYS6yn69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizes the text and prepares the audio features\n",
        "class HumorDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=32):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            row[\"transcript\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        audio_feats = torch.tensor([[row[\"audio_feature1\"], row[\"audio_feature2\"]]], dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"audio_feats\": audio_feats,\n",
        "            \"score\": torch.tensor(row[\"humor_score\"], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "Ofqmr6J4yqST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The code defines a multimodal deep learning model for humor regression that processes both textual data (from BERT) and audio features (numerical data).\n",
        "# The goal of the model is to predict a humor score based on these two input modalities.\n",
        "\n",
        "#This class is used to perform cross-modal attention, where the model learns to attend to both textual and audio features simultaneously.\n",
        "class CrossModalAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=4, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, query, key_value):\n",
        "        attn_output, _ = self.attn(query, key_value, key_value)\n",
        "        return self.norm(query + attn_output)\n",
        "\n",
        "\n",
        "class HumorRegressor(nn.Module):\n",
        "    def __init__(self, text_hidden_size=768, audio_feat_size=2, fusion_dim=128):\n",
        "        super().__init__()\n",
        "        # Load pre-trained BERT model\n",
        "        self.text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        # Projection layer for audio features to match the hidden size of text model\n",
        "        self.audio_proj = nn.Linear(audio_feat_size, text_hidden_size)\n",
        "\n",
        "        # Cross-modal attention layer (if needed)\n",
        "        self.cross_attn = CrossModalAttention(text_hidden_size)\n",
        "\n",
        "        # Fusion layer to combine text and audio features\n",
        "        self.fusion = nn.Linear(text_hidden_size + audio_feat_size, fusion_dim)  # +audio_feat_size to match the concatenated size\n",
        "\n",
        "        # Final regressor layer\n",
        "        self.regressor = nn.Linear(fusion_dim, 1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, audio_feats):\n",
        "      # Pass through the BERT model\n",
        "      text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      text_hidden = text_outputs.last_hidden_state  # shape: (batch_size, seq_len, hidden_size)\n",
        "\n",
        "      # Extract the [CLS] token (first token in the sequence) for pooling\n",
        "      pooled = text_hidden[:, 0, :]  # shape: (batch_size, hidden_size)\n",
        "\n",
        "      # Ensure audio_feats has shape (batch_size, 1, 2) and remove extra dimensions\n",
        "      audio_feats = audio_feats.squeeze(1)  # shape: (batch_size, 2) now\n",
        "\n",
        "      # Concatenate the [CLS] token with the audio features\n",
        "      merged_features = torch.cat((pooled, audio_feats), dim=1)  # shape: (batch_size, hidden_size + 2)\n",
        "\n",
        "      # Apply the fusion layer\n",
        "      fused_hidden = self.fusion(merged_features)  # shape: (batch_size, fusion_dim)\n",
        "\n",
        "      # Predict the humor score using the regressor\n",
        "      score = self.regressor(fused_hidden)  # shape: (batch_size, 1)\n",
        "\n",
        "      return score.squeeze(1)  # return a 1D tensor (batch_size,)\n"
      ],
      "metadata": {
        "id": "hn7YU6Mp2Cg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- Step 4: Training Loop ----------------\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        audio_feats = batch[\"audio_feats\"].to(device)\n",
        "        labels = batch[\"score\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask, audio_feats)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "L7kI1VhP-IIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- Step 5: Setup and Run ----------------\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "dataset = HumorDataset(df, tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "1yZMEXOl-YAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcEeatNlGlN2",
        "outputId": "13c40171-9312-4b4d-c80f-5a6e15b4ac3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = HumorRegressor().to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "model.parameters()"
      ],
      "metadata": {
        "id": "XSPKmGHQG06I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for a few epochs\n",
        "for epoch in range(3):\n",
        "    loss = train(model, dataloader, optimizer, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx4soLyyGySc",
        "outputId": "a637f4f3-8049-41f0-c41f-61456a00bf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.8145\n",
            "Epoch 2, Loss: 2.6573\n",
            "Epoch 3, Loss: 1.3137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample record-level validation data\n",
        "record_data_val = pd.DataFrame({\n",
        "    \"record_id\": [0, 1],\n",
        "    \"transcript\": [\"I like dogs\", \"He is funny\"],\n",
        "\n",
        "    \"humor_type\": [3, 1],\n",
        "    \"humor_score\": [2.0, 3.0]\n",
        "})\n",
        "\n",
        "audio_features_val = pd.DataFrame({\n",
        "    \"record_id\": [0, 1],\n",
        "    \"audio_feature1\": [0.08, 0.51],\n",
        "    \"audio_feature2\": [0.51, 0.19]\n",
        "})\n"
      ],
      "metadata": {
        "id": "rx2dl_ejWhrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "\n",
        "# Create a dataset for the validation set in the same way as training data\n",
        "df_val = pd.merge(record_data_val, audio_features_val, on=\"record_id\")\n",
        "val_dataset = HumorDataset(df_val, tokenizer)\n",
        "\n",
        "# Create a DataLoader for validation\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# Evaluate the model's performance on validation set\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "    for batch in val_dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        audio_feats = batch[\"audio_feats\"].to(device)\n",
        "        labels = batch[\"score\"].to(device)  # Ground truth labels (humor score)\n",
        "\n",
        "        # Get the model's predictions\n",
        "        outputs = model(input_ids, attention_mask, audio_feats)\n",
        "\n",
        "        # Append the true and predicted values\n",
        "        predicted_labels.extend(outputs.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rwtxb3VWvMK",
        "outputId": "3cf1fb36-84fc-488d-d6ab-1b978e2f616b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 1.0536\n",
            "R-squared: -3.2142\n"
          ]
        }
      ]
    }
  ]
}